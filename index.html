<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="Dreamweaver"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="https://cun-bjy.github.io/dreamweaver-website/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Dreamweaver</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> TODO -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Dreamweaver: Learning Compositional World Representations from Pixels</h1>
          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block-kaist">
              <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Junyeob Baek</a><sup>1</sup>,</span>
            <span class="author-block-rutgers">
              <a href="https://www.yifuwu.com/" target="_blank">Yi-Fu Wu</a><sup>2</sup>,</span>
            <span class="author-block-rutgers">
              <a href="https://singhgautam.github.io/" target="_blank">Gautam Singh</a><sup>2</sup>,</span>
            <span class="author-block-kaist">
              <a href="https://mlml.kaist.ac.kr/sungjinahn" target="_blank">Sungjin Ahn</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block-kaist"><sup>1</sup>KAIST,</span>
            <span class="author-block-rutgers"><sup>2</sup>Rutgers Univercity</span>
            <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
          </div>

          <div class="is-size-5 iclr-year">
            <span class="author-block" style="font-size: 1.25em;">ðŸ’«ICLR 2025ðŸŽ‰</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Arxiv PDF link -->
              <span class="link-block">
                  <a href="https://arxiv.org/abs/2501.14174" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Supplementary PDF link -->
              <!-- <span class="link-block">
                <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Supplementary</span>
              </a> 
              </span> -->

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/YOUR REPO HERE" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code (soon)</span>
              </a>
              </span>

              <!-- ArXiv abstract Link -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/images/teaser_1.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
            <p style="font-size: 1.3em;">
            Humans have an innate ability to decompose their perceptions of the world into objects and their attributes, such as colors, shapes, and movement patterns. This cognitive process enables us to imagine novel futures by recombining familiar concepts. However, replicating this ability in artificial intelligence systems has proven challenging, particularly when it comes to modeling videos into compositional concepts and generating unseen, recomposed futures without relying on auxiliary data, such as text, masks, or bounding boxes. In this paper, we propose <b>Dreamweaver, a neural architecture designed to discover hierarchical and compositional representations from raw videos and generate compositional future simulations.</b> Our approach leverages a novel Recurrent Block-Slot Unit (RBSU) to decompose videos into their constituent objects and attributes. In addition, Dreamweaver uses a multi-future-frame prediction objective to capture disentangled representations for dynamic concepts more effectively as well as static concepts. In experiments, we demonstrate our model outperforms current state-of-the-art baselines for world modeling when evaluated under the DCI framework across multiple datasets. Furthermore, we show how the modularized concept representations of our model enable compositional imagination, allowing the generation of novel videos by recombining attributes from different objects.
            </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Dreamweaver Framework -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Dreamweaver Framework</h2>

        <div class="content has-text-justified">
          <img src="static/images/figure-one.png" alt="Dreamweaver Framework"/>
          <p class="caption" style="font-size: 1.2em;">Our aim is to take a sequential unstructured sensory
            stream and bind the low-level information into abstract modular concepts to build a memory of reusable concepts,
            called concept libraryâ€”all without text and in an unsupervised way. These concepts include both static factors
            such as color and shape as well as dynamic factors such as direction and speed of motion. Finally, we seek to
            recombine these concepts, e.g., in a novel configuration, and imagine an unseen world.</p>
        </div>
      </div>
    </div>
  </div>
  <!-- Horizontal Bar -->
  <div class="container is-max-desktop">
    <br><hr><br>
  </div>

<!-- Architecture Section -->
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Architecture</h2>

        <div class="content has-text-justified">
          <img src="static/images/arch.png" alt="Dreamweaver Architecture"/>
          <p class="caption" style="font-size: 1.2em;"><i>Left</i>: The Recurrent Block-Slot Unit (RBSU) is a recurrent unit designed
            for processing sequences where each item is a set of vectors. RBSU maintains and updates Block-Slots,
            which represent compositional and semantic concepts such as shape, color, and motion direction. <i>Right</i>: The
            Dreamweaver model encodes video inputs into Block-Slot representations, which pass through a series of
            RBSUs with a recurrent structure. It then predicts future frames by decoding the extracted Block-Slots using a
            transformer decoder, training to minimize the predictive objective.</p>
        </div>
      </div>
    </div>
  </div>

<!-- Horizontal Bar -->
  <div class="container is-max-desktop">
    <br><hr><br>
  </div>

<!-- Concept Discovery Section -->
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Unsupervised Modular Concept Discovery from Videos</h2>
        <p class="caption" style="font-size: 1.5em;">(1) DCI Performance</p>
        <div class="content has-text-justified">
          <img src="static/images/dci_graph_iclr.png" alt="Concept Discovery"/>
          <p class="caption" style="font-size: 1.2em;">
            We compare our model with the baselines in terms of Disentanglement (D), Completeness (C), Informativeness (I), and Informativeness-Dynamic (I-D). I-D is the informativeness score for dynamic concepts only (e.g., direction of motion or dance patterns) to evaluate how effectively the models capture such dynamic concepts.
          </p>
        </div>
      </div>
      </div>
    </div>
  </div>

<!-- Clustering Visualization -->
  <div class="hero-body">
    <div class="container is-max-desktop">
      <p class="caption" style="font-size: 1.5em;">(2) Visualizing Captured Concepts</p>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/clustering_sprites.png" alt="Concept Examples 1"/>
        <h2 class="subtitle has-text-centered">
            <br><br><b>Moving-Sprites Dataset</b>
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/clustering_clevr.png" alt="Concept Examples 2"/>
        <h2 class="subtitle has-text-centered">
            <br><br><b>Dancing-CLEVR Dataset</b>
        </h2>
      </div>
  </div>
  
  <p class="caption" style="font-size: 1.2em;">
    This illustrates the concepts represented by each block within the learned block-slot representations. To achieve this, we gather block representations with the same index and apply clustering methods, such as k-means, following the approach in <a href="https://arxiv.org/abs/2211.01177">Singh et al. (2023)</a>.
  </p>
</div>
</div>
<!-- End Clustering Visualization -->

<!-- Horizontal Bar -->
  <div class="container is-max-desktop">
    <hr><br>
  </div>

<!-- Compositional Imagination -->
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Compositional Imagination</h2>
        
        <div class="content has-text-justified">
          <img src="static/images/compositional-imagination.png" alt="Compositional Imagination"/>
          <p class="caption" style="font-size: 1.2em;">
            We show compositionally novel videos generated by Dreamweaver. In this visualization, we (1) infer the block-slot representation given an initial context video, (2) perform manipulations on the inferred block-slot representation, and (3) perform rollout starting from the manipulated block-slot representation. At the top, we also visualize the rollout that would have occurred had no manipulation been done to the representation. <i>Left</i>: For the Moving-Sprites dataset, we visualize manipulations such as swapping color and shape, changing of direction of motion of a specific object, and changing the speed of movement of a specific object. <i>Right</i>: For the Dancing-CLEVR dataset, we visualize manipulations such as swapping the object shapes and changing the dance patterns.
          </p>
        </div>
      </div>
    </div>
  </div>

<!-- Horizontal Bar -->
  <div class="container is-max-desktop">
    <br><hr><br>
  </div>

<!-- Compositional Scene Prediction and Reasoning -->
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Compositional Scene Prediction and Reasoning</h2>

        <div class="content has-text-justified">
          <img src="static/images/downstream.png" alt="Scene Prediction Results"/>
          <p class="caption" style="font-size: 1.2em;">
            We compare our model with baselines in terms of prediction accuracy for different frame offsets. A frame offset of zero corresponds to the last context frame and a frame offset of one corresponds to the first predicted frame after the context frames, and so on.
          </p>
        </div>
      </div>
    </div>
  </div>

<!-- Presentation video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Horizontal Bar -->
  <div class="container is-max-desktop">
    <br><hr>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{baek2025dreamweaver,
        title={Dreamweaver: Learning Compositional World Representations from Pixels},
        author={Baek, Junyeob and Wu, Yi-Fu and Singh, Gautam and Ahn, Sungjin},
        journal={arXiv preprint arXiv:2501.14174},
        year={2025}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page. This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
